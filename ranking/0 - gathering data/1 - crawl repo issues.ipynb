{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from datetime import datetime\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "labels_cat = {\"critical_priority\", \"high_priority\", \"medium_priority\", \"low_priority\"}\n",
    "\n",
    "for label_cat in labels_cat:\n",
    "    with open(f\"../data/{label_cat}_issues.txt\") as f:\n",
    "        obj = json.loads(f.read())\n",
    "        dataframes[label_cat] = pd.DataFrame(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_conn = 10\n",
    "\n",
    "clients = [('your_clinet_id_1', 'your_clinet_secret_1'),\n",
    "           ('your_clinet_id_2', 'your_clinet_secret_2'),\n",
    "           ('...', '...')]\n",
    "\n",
    "clients_number = len(clients)          \n",
    "headers = {}\n",
    "headers['Accept'] = 'application/vnd.github.starfox-preview+json'\n",
    "\n",
    "#chunk_size = rate_limit*clients_number/requests_per_issue\n",
    "#rate_limit = 5000\n",
    "#clients_number = 5\n",
    "#requests_per_issue =~ 5 #chon axare issue ha bishtar az 100 ta cm ya event nadaran, baraye taghirban hamashun bishtar az 5 ta req dade nmishe\n",
    "chunk_size = 4000\n",
    "\n",
    "def get_data(req_url):\n",
    "    number_of_tries = 10\n",
    "    try:   \n",
    "        r = requests.get(req_url, headers=headers)\n",
    "        if(r.ok):            \n",
    "            result = json.loads(r.text or r.content)            \n",
    "            \n",
    "            # check for max limit\n",
    "            try:\n",
    "                if int(r.headers[\"X-RateLimit-Remaining\"]) < 10:\n",
    "                    print(\"limit exceeded!!!!!!!!!!!!\")\n",
    "                    delay = float(r.headers[\"X-RateLimit-Reset\"]) - time.mktime(time.localtime())#.total_seconds()\n",
    "                    print('sleeping for '+str(delay)+' seconds...')\n",
    "                    print(\"current time:\" + str(datetime.now()))\n",
    "                    time.sleep(int(delay))\n",
    "            except (KeyError):\n",
    "                pass \n",
    "            \n",
    "            return result\n",
    "        \n",
    "        else:\n",
    "            j = json.loads(r.text or r.content)\n",
    "            print('\\n---'+str(r))\n",
    "            print('\\n---'+str(j['message']))\n",
    "            return False\n",
    "    except requests.exceptions.Timeout as e:\n",
    "        print(\"-------timeout-------\")\n",
    "        print(e)\n",
    "        number_of_tries-=1\n",
    "        if(number_of_tries):\n",
    "            time.sleep(delay_conn)\n",
    "            get_data(req_url)\n",
    "        else:\n",
    "            sys.exit(1)\n",
    "    except requests.ConnectionError as e:\n",
    "        print(\"-------connection error-------\")\n",
    "        print(e)\n",
    "        number_of_tries-=1\n",
    "        if(number_of_tries):\n",
    "            time.sleep(delay_conn)\n",
    "            get_data(req_url)\n",
    "        else:\n",
    "            sys.exit(1)\n",
    "\n",
    "def get_data_pages(req_url):    \n",
    "    page_number = 1\n",
    "    resp_list = [] \n",
    "    \n",
    "    while(True):         \n",
    "        number_of_tries = 10\n",
    "        try:   \n",
    "            r = requests.get(req_url + \"&page=\" + str(page_number), headers=headers)            \n",
    "            if(r.ok):                            \n",
    "                result = json.loads(r.text or r.content)\n",
    "                resp_list += result            \n",
    "\n",
    "                if not result:\n",
    "                    break\n",
    "                \n",
    "                if(len(result)<100):\n",
    "                    break\n",
    "                    \n",
    "                page_number += 1\n",
    "                    \n",
    "                # check for max limit\n",
    "                try:\n",
    "                    if int(r.headers[\"X-RateLimit-Remaining\"]) < 10:\n",
    "                        print(\"limit exceeded!!!!!!!!!!!!\")\n",
    "                        delay = float(r.headers[\"X-RateLimit-Reset\"]) - time.mktime(time.localtime())#.total_seconds()\n",
    "                        print('sleeping for '+str(delay)+' seconds...')\n",
    "                        print(\"current time:\" + str(datetime.now()))\n",
    "                        time.sleep(int(delay))\n",
    "                except (KeyError):\n",
    "                    pass            \n",
    "            else:\n",
    "                j = json.loads(r.text or r.content)\n",
    "                print('\\n---'+str(r))\n",
    "                print('\\n---'+str(j['message']))\n",
    "                return False\n",
    "        except requests.exceptions.Timeout as e:\n",
    "            print(\"-------timeout-------\")\n",
    "            print(e)\n",
    "            number_of_tries-=1\n",
    "            if(number_of_tries):\n",
    "                time.sleep(delay_conn)\n",
    "                get_data_pages(req_url)\n",
    "            else:\n",
    "                sys.exit(1)\n",
    "        except requests.ConnectionError as e:\n",
    "            print(\"-------connection error-------\")\n",
    "            print(e)\n",
    "            number_of_tries-=1\n",
    "            if(number_of_tries):\n",
    "                time.sleep(delay_conn)\n",
    "                get_data_pages(req_url)\n",
    "            else:\n",
    "                sys.exit(1)\n",
    "    return resp_list\n",
    "\n",
    "def get_issues(repo, repo_cat_map):\n",
    "    repo_address = 'https://api.github.com/repos/' + repo\n",
    "    issues_list = []\n",
    "    for cat in repo_cat_map:\n",
    "        cat_df = dataframes[cat]\n",
    "        issue_numbers = list(cat_df[cat_df.repository_url == repo_address].number)\n",
    "        issues_list += list(zip(issue_numbers, [cat]*len(issue_numbers)))\n",
    "        \n",
    "    df_size = len(issues_list)\n",
    "    client_index = 0    \n",
    "    chunks_number = df_size//chunk_size if df_size//chunk_size == df_size/chunk_size else df_size//chunk_size+1\n",
    "       \n",
    "    for i in range(chunks_number):\n",
    "        print(\"****chunk number: \" + str(i) + \"****\")\n",
    "        batch_start_time = datetime.now()\n",
    "        issues = []\n",
    "        for (number, cat) in issues_list[i*chunk_size:(i+1)*chunk_size]:\n",
    "            client_id, client_secret = clients[client_index]\n",
    "            print(number)\n",
    "            \n",
    "            issue_req = \"https://api.github.com/repos/\" + repo + \"/issues/\" + str(number) + \"?client_id=\" + client_id + \"&client_secret=\" + client_secret  \n",
    "            issue_obj = get_data(issue_req)\n",
    "            \n",
    "            if issue_obj:\n",
    "                closer_obj = np.nan\n",
    "                if issue_obj[\"closed_by\"]:\n",
    "                    closer = issue_obj[\"closed_by\"][\"login\"]\n",
    "                    user_req = \"https://api.github.com/users/\" + closer + '?client_id=' + client_id + '&client_secret=' + client_secret\n",
    "                    closer_obj = get_data(user_req)        \n",
    "\n",
    "                author = issue_obj[\"user\"][\"login\"]\n",
    "                user_req = \"https://api.github.com/users/\" + author + '?client_id=' + client_id + '&client_secret=' + client_secret\n",
    "                author_obj = get_data(user_req)\n",
    "\n",
    "                events_req = \"https://api.github.com/repos/\" +  repo + \"/issues/\" + str(number) + \"/events?per_page=100\" + '&client_id=' + client_id + '&client_secret=' + client_secret\n",
    "                events_obj = get_data_pages(events_req)\n",
    "\n",
    "                comments_req = \"https://api.github.com/repos/\" + repo + \"/issues/\" + str(number) + \"/comments?per_page=100\" + '&client_id=' + client_id + '&client_secret=' + client_secret\n",
    "                comments_obj = get_data_pages(comments_req)\n",
    "\n",
    "            client_index += 1\n",
    "            if(client_index == clients_number):\n",
    "                client_index = 0 \n",
    "\n",
    "            if(issue_obj == False or closer_obj == False or author_obj == False or events_obj == False or comments_obj==False):\n",
    "                print(\"\\n-------some problem with this issue!-------\")\n",
    "            else:\n",
    "                issues.append({\"number\":number, \"repo\":repo, \"actual_label_cat\":cat, \"repo_label_cat\": repo_cat_map[cat], \"issue_obj\":json.dumps(issue_obj), \"author_obj\":json.dumps(author_obj), \"closer_obj\":json.dumps(closer_obj), \"events_obj\":json.dumps(events_obj), \"comments_obj\":json.dumps(comments_obj)})\n",
    "        issues_df = pd.DataFrame(issues)\n",
    "        issues_df.to_csv(\"../data/\"+repo.split('/')[1]+\"_\"+str(i)+\".csv\", index=False)\n",
    "        print(\"------batch \"+str(i+1)+\" completed------\")\n",
    "        batch_end_time = datetime.now()\n",
    "        duration = (batch_end_time - batch_start_time).seconds\n",
    "        if(duration < 3600 and i != chunks_number-1):\n",
    "            print(\"----sleep time: \" + str(duration) + \"----\")\n",
    "            time.sleep(3600 - duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = \"eclipse-ee4j/jersey\"\n",
    "repo_cat_map = {\"critical_priority\":\"high_priority\", \"high_priority\":\"medium_priority\", \"low_priority\":\"low_priority\"}   #{actual_cat: repo_cat}\n",
    "\n",
    "print(\"Starting time:\" + str(datetime.now()))\n",
    "get_issues(repo, repo_cat_map)\n",
    "print(\"End time:\" + str(datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
