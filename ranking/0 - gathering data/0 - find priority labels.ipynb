{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "from requests.auth import HTTPBasicAuth\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "import sys\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_priority = [\n",
    "\"priority: blocker\",\n",
    "# \"criticalpriority\",\n",
    "\"priority-critical\",\n",
    "\"critical priority\",\n",
    "\"priority:critical\",\n",
    "\"priority critical\",\n",
    "\"priority: critical\",\n",
    "\"priority - critical\",\n",
    "\"critical-priority\",\n",
    "\"priority/urgent\",\n",
    "\"priority/blocker\",\n",
    "\"priority/critical\",\n",
    "\"priority/important\",\n",
    "\"critical\",\n",
    "\"important\",\n",
    "\"urgent\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_priority = [\n",
    "\"priority: major\",\n",
    "\"highpriority\",\n",
    "\"priority-high\",\n",
    "\"high priority\",\n",
    "\"priority:high\",\n",
    "\"priority high\",\n",
    "\"priority: high\",\n",
    "\"priority - high\",\n",
    "\"high-priority\",\n",
    "\"priority/high\",\n",
    "\"is:priority\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_priority = [\n",
    "\"priority:normal\",\n",
    "\"mediumpriority\",\n",
    "\"priority-medium\",\n",
    "\"medium priority\",\n",
    "\"priority:medium\",\n",
    "\"priority medium\",\n",
    "\"priority: medium\",\n",
    "\"priority - medium\",\n",
    "\"medium-priority\",\n",
    "\"priority/medium\",\n",
    "\"priority/normal\",\n",
    "\"priority: middle\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_priority = [\n",
    "\"priority: minor\",\n",
    "\"lowpriority\",\n",
    "\"priority-low\",\n",
    "\"low priority\",\n",
    "\"priority:low\",\n",
    "\"priority low\",\n",
    "\"priority: low\",\n",
    "\"priority - low\",\n",
    "\"low-priority\",\n",
    "\"priority/low\",\n",
    "\"is:no-priority\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wontfix = [\n",
    "\"priority: trivial\",\n",
    "\"won't fix\",\n",
    "\"wont fix\",\n",
    "\"wontfix\",\n",
    "\"wont-fix\",\n",
    "\"status: won't fix\",\n",
    "\"will not fix\",\n",
    "\"resolution:won't fix\",\n",
    "\"status=will-not-fix\",\n",
    "\"closed: won't fix\",\n",
    "\"state:wont-fix\",\n",
    "\"status: will not fix\",\n",
    "\"won't-fix\",\n",
    "\"will-not-fix\",\n",
    "\"cant-fix\",\n",
    "\"cantfix\",\n",
    "\"can't fix\",\n",
    "\"rejected\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = {\"critical_priority\":critical_priority, \"high_priority\":high_priority, \"medium_priority\":medium_priority, \"low_priority\":low_priority, \"wontfix\":wontfix}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_conn = 60\n",
    "clients = [('your_clinet_id_1', 'your_clinet_secret_1'),\n",
    "           ('your_clinet_id_2', 'your_clinet_secret_2'),\n",
    "           ('...', '...')]\n",
    "\n",
    "clients_number = len(clients)          \n",
    "client_index = 0\n",
    "headers = {}\n",
    "headers['User-Agent'] = \"Mozilla/5.0 (X11; Linux i686) AppleWebKit/537.17 (KHTML, like Gecko) Chrome/24.0.1312.27 Safari/537.17\"\n",
    "headers['Accept'] = 'Accept: application/vnd.github.squirrel-girl-preview'\n",
    "\n",
    "def get_data_pages(req_url, upper_bound=math.inf, key=-1):    \n",
    "    page_number = 1\n",
    "    resp_list = [] \n",
    "    \n",
    "    while(page_number<=upper_bound):         \n",
    "        try:   \n",
    "            r = requests.get(req_url + \"&page=\" + str(page_number), headers=headers) \n",
    "            if(r.ok):                            \n",
    "                result = json.loads(r.text or r.content)\n",
    "                \n",
    "                if key == -1: \n",
    "                    data = result                        \n",
    "                else:\n",
    "                    if not key in result:\n",
    "                        print(\"key not exists\")    \n",
    "                        break                    \n",
    "                    data = result[key]\n",
    "\n",
    "                resp_list += data          \n",
    "                if not data:\n",
    "                    break\n",
    "                page_number += 1\n",
    "                    \n",
    "                try:\n",
    "                    if int(r.headers[\"X-RateLimit-Remaining\"]) < 2:\n",
    "                        print(\"limit exceeded!!!!!!!!!!!!\")\n",
    "                        delay = 60\n",
    "                        print('sleeping for '+str(delay)+' seconds...')\n",
    "                        print(\"current time:\" + str(datetime.now()))\n",
    "                        time.sleep(int(delay))\n",
    "                except (KeyError):\n",
    "                    pass            \n",
    "            else:\n",
    "                resp = json.loads(r.text or r.content)\n",
    "                print('\\n---'+str(r))\n",
    "                print('\\n---'+str(resp['message']))\n",
    "                return False\n",
    "        except requests.exceptions.Timeout as e:\n",
    "            print(\"-------timeout-------\")\n",
    "            print(e)\n",
    "            time.sleep(delay_conn)\n",
    "            return get_data_pages(req_url, upper_bound, key)\n",
    "        except requests.ConnectionError as e:\n",
    "            print(\"-------connection error-------\")\n",
    "            print(e)\n",
    "            time.sleep(delay_conn)\n",
    "            return get_data_pages(req_url, upper_bound, key)\n",
    "    return resp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = clients_number*3  #in each 1000 issue batch, we request 10 pages, so we can crawl 3 batch per minute with each client\n",
    "start_time = datetime.now()\n",
    "\n",
    "for label_cat in [\"critical_priority\", \"wontfix\"]:\n",
    "    cat_issues = []\n",
    "    for label in all_labels[label_cat]:\n",
    "        start_time = datetime.now() \n",
    "        last_date = '2020-11-10T10:23:19Z'\n",
    "        issues_list = []\n",
    "        batch_number = 1\n",
    "        while True:    \n",
    "            client_id, client_secret = clients[client_index]\n",
    "            issues_req = f'https://api.github.com/search/issues?q=label:\"{label}\"+state:closed+created:<{last_date}+language:java&sort=created&per_page=100&client_id={client_id}&client_secret={client_secret}'\n",
    "            batch_issues_list = get_data_pages(issues_req, 10, \"items\")\n",
    "\n",
    "            if not batch_issues_list:\n",
    "                break\n",
    "\n",
    "            client_index += 1\n",
    "            if(client_index == clients_number):\n",
    "                client_index = 0\n",
    "\n",
    "            last_date = batch_issues_list[-1][\"created_at\"]\n",
    "            issues_list += batch_issues_list\n",
    "            batch_number += 1\n",
    "            \n",
    "            counter -= 1\n",
    "            if counter == 0:\n",
    "                end_time = datetime.now()\n",
    "                duration = (end_time - start_time).seconds\n",
    "                if(duration < 60):\n",
    "                    time.sleep(60 - duration)\n",
    "                    print(f\"sleep for {60 - duration} seconds\")\n",
    "            counter = clients_number*3\n",
    "            start_time = datetime.now()\n",
    "\n",
    "        print(label, len(issues_list))\n",
    "        if(issues_list == []):\n",
    "            print(f\"there is no issue for label {label}\")\n",
    "            \n",
    "        cat_issues += issues_list\n",
    "\n",
    "    with open(f\"data/{label_cat}_issues.txt\", \"w\") as f:\n",
    "        f.write(json.dumps(cat_issues, indent=4))\n",
    "\n",
    "print(\"\\n*********finished*********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label_cat in all_labels:\n",
    "    with open(f\"data/{label_cat}_issues.txt\") as f:\n",
    "        obj = json.loads(f.read())\n",
    "        print(label_cat, len(obj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelcat_repos = {}\n",
    "for label_cat in all_labels:\n",
    "    with open(f\"data/{label_cat}_issues.txt\") as f:\n",
    "        obj = json.loads(f.read())\n",
    "    labelcat_repos[label_cat] = [i[\"repository_url\"] for i in obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p123 = list(set([repo for repo in label_repos[\"p1\"] if repo in label_repos[\"p2\"] and repo in label_repos[\"p3\"]]))\n",
    "\n",
    "all_repos = [] \n",
    "for label_cat in all_labels:\n",
    "    all_repos += labelcat_repos[label_cat]\n",
    "all_repos = list(set(all_repos))\n",
    "\n",
    "print(len(all_repos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_count = {label_cat:[] for label_cat in all_labels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo in all_repos:\n",
    "    for label_cat in all_labels:\n",
    "        p_count[label_cat].append(labelcat_repos[label_cat].count(repo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = [\"repo\"] + [label_cat for label_cat in all_labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"repo\"] = all_repos\n",
    "for label_cat in all_labels:\n",
    "    df[label_cat] = p_count[label_cat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/repos_priority_labels.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
