{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Adding fasttext probs and sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/repos/3/allrepos_processed.csv\")\n",
    "senti = pd.read_csv(\"../data/repos/3/allrepos_sentiments.csv\")\n",
    "ftprobs = pd.read_csv(\"../data/repos/3/allrepos_ftprobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ft_bug\"] = ftprobs[\"__label__bug\"] \n",
    "df[\"ft_feature\"] = ftprobs[\"__label__feature\"] \n",
    "df[\"ft_other\"] = ftprobs[\"__label__other\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_sentistrenght_p\"] = senti[\"title_sentistrenght\"].apply(lambda x: x.split(',')[0])\n",
    "df[\"title_sentistrenght_n\"] = senti[\"title_sentistrenght\"].apply(lambda x: x.split(',')[1])\n",
    "\n",
    "df[\"body_sentistrenght_p\"] = senti[\"body_sentistrenght\"].apply(lambda x: x.split(',')[0])\n",
    "df[\"body_sentistrenght_n\"] = senti[\"body_sentistrenght\"].apply(lambda x: x.split(',')[1])\n",
    "\n",
    "df[\"title_polarity\"] = senti[\"title_textblob\"].apply(lambda x: x.split(',')[0])\n",
    "df[\"title_subjectivity\"] = senti[\"title_textblob\"].apply(lambda x: x.split(',')[1])\n",
    "\n",
    "df[\"body_polarity\"] = senti[\"body_textblob\"].apply(lambda x: x.split(',')[0])\n",
    "df[\"body_subjectivity\"] = senti[\"body_textblob\"].apply(lambda x: x.split(',')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"positive_title_sentistrenght_n\"] = df[\"title_sentistrenght_n\"].astype(int).abs()\n",
    "df[\"positive_body_sentistrenght_n\"] = df[\"body_sentistrenght_n\"].astype(int).abs()\n",
    "df[\"positive_title_polarity\"] = df[\"title_polarity\"].astype(float) + 1\n",
    "df[\"positive_body_polarity\"] = df[\"body_polarity\"].astype(float) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Applynig some other preprocessings and adding some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.closer_login.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_time_interval(t1, t2):\n",
    "    d1 = datetime.strptime(t1, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    d2 = datetime.strptime(t2, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    delta = d2-d1\n",
    "    return delta.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_time = df.created_at.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"author_account_age\"] = df[\"author_created_at\"].apply(lambda x: round(compute_time_interval(x, base_time)/365))    \n",
    "df[\"closer_account_age\"] = df[\"closer_created_at\"].apply(lambda x: round(compute_time_interval(x, base_time)/365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"has_assignee\"] = ~df[\"assignee\"].isna()\n",
    "df[\"num_of_assignees\"] = df[\"assignees\"].apply(lambda x: 0 if pd.isna(x) else len(x.split(\"|\")))\n",
    "df['has_milestone'] = df['milestone'].apply(lambda x: 0 if pd.isna(x) else 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"author_github_cntrb\"] = df[\"author_github_cntrb\"].apply(lambda x: int(str(x).replace(',','')))\n",
    "df[\"closer_github_cntrb\"] = df[\"closer_github_cntrb\"].apply(lambda x: int(str(x).replace(',','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['numeric_association'] = df['author_association'].apply(lambda x: 0 if x == \"NONE\"  else 1 if x == \"CONTRIBUTOR\" else 2 if x == \"MEMBER\" else 3 if x == \"OWNER\" else 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df[(df.repository == \"spring-framework\") & (df.author_login == \"spring-issuemaster\")].shape)\n",
    "# print(df[(df.repository == \"spring-framework\") & (df.author_login != \"spring-issuemaster\")].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df[(df.repository == \"spring-framework\") & (df.closer_login == \"spring-issuemaster\")].shape)\n",
    "# print(df[(df.repository == \"spring-framework\") & (df.closer_login != \"spring-issuemaster\")].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df[(df.repository == \"spring-framework\") & (df.author_login == \"spring-issuemaster\") & (df.closer_login == \"spring-issuemaster\")].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"author_creation_day_before_issue\"] = df.apply(lambda x: np.nan if x.author_login == \"spring-issuemaster\" else compute_time_interval(x.author_created_at, x.created_at) ,axis=1)\n",
    "# df[\"tyro_author\"] = df[\"author_creation_day_before_issue\"].apply(lambda x: 1 if x<5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "spring-framework has a spring-issuemaster author which owns 17005 issues form total 19719 issues!!\n",
    "this user also closed 16900 issues of spring-framework and 230 issues from spring-boot\n",
    "spring-issuemaster doesnt have any repo and star, thus considering author info for spring-framework repo is meaningless\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3132, 112)\n",
      "(1609, 112)\n",
      "(1344, 112)\n",
      "(1344, 112)\n"
     ]
    }
   ],
   "source": [
    "print(df[df.repository == \"guava\"].shape)\n",
    "print(df[(df.repository == \"guava\") & (df.author_login == \"gissuebot\")].shape)\n",
    "print(df[(df.repository == \"guava\") & (df.closer_login == \"gissuebot\")].shape)\n",
    "print(df[(df.repository == \"guava\") & (df.author_login == \"gissuebot\") & (df.closer_login == \"gissuebot\")].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6084, 112)\n",
      "(50, 112)\n",
      "(1, 112)\n",
      "(1, 112)\n"
     ]
    }
   ],
   "source": [
    "print(df[df.repository == \"RxJava\"].shape)\n",
    "print(df[(df.repository == \"RxJava\") & (df.author_login == \"dependabot-preview[bot]\")].shape)\n",
    "print(df[(df.repository == \"RxJava\") & (df.closer_login == \"dependabot-preview[bot]\")].shape)\n",
    "print(df[(df.repository == \"RxJava\") & (df.author_login == \"dependabot-preview[bot]\") & (df.closer_login == \"dependabot-preview[bot]\")].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2960, 112)\n",
      "(2, 112)\n",
      "(0, 112)\n",
      "(0, 112)\n"
     ]
    }
   ],
   "source": [
    "print(df[df.repository == \"retrofit\"].shape)\n",
    "print(df[(df.repository == \"retrofit\") & (df.author_login == \"dependabot[bot]\")].shape)\n",
    "print(df[(df.repository == \"retrofit\") & (df.closer_login == \"dependabot[bot]\")].shape)\n",
    "print(df[(df.repository == \"retrofit\") & (df.author_login == \"dependabot[bot]\") & (df.closer_login == \"dependabot[bot]\")].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns[df.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33582, 112)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.reaction_time.isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101552, 112)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "elasticsearch       44099\n",
       "spring-framework    19717\n",
       "spring-boot         15254\n",
       "okhttp              10306\n",
       "RxJava               6084\n",
       "guava                3132\n",
       "retrofit             2960\n",
       "Name: repository, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.repository.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "base_repos = ['elasticsearch', 'spring-framework', 'spring-boot', 'okhttp', 'RxJava', 'guava', 'retrofit']\n",
    "corss_repos = [\"corss_7\", \"cross_without_sf\", \"cross_without_bot\", \"cross_without_sf_el\", \"cross_without_bot_el\"]\n",
    "repos = base_repos + corss_repos\n",
    "reaction_time_med = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframes[\"elasticsearch\"] =  df[df.repository == \"elasticsearch\"]\n",
    "# dataframes[\"spring-boot\"] =  df[(df.repository == \"spring-boot\") & (df.closer_login != \"spring-issuemaster\")]\n",
    "# dataframes[\"spring-framework\"] =  df[(df.repository == \"spring-framework\") & (df.author_login == \"spring-issuemaster\") & (df.closer_login == \"spring-issuemaster\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticsearch 1.9916666666666663\n",
      "spring-framework 1346.7\n",
      "spring-boot 46.25\n",
      "okhttp 126.29166666666667\n",
      "RxJava 13.316666666666665\n",
      "guava 454.3333333333333\n",
      "retrofit 168.63333333333333\n"
     ]
    }
   ],
   "source": [
    "for repo in base_repos:\n",
    "    dataframes[repo] = df[df.repository == repo]\n",
    "    reaction_time_med[repo] = dataframes[repo].reaction_time.median()\n",
    "    print(repo, reaction_time_med[repo])\n",
    "    dataframes[repo].to_csv(f\"../data/repos/final/{repo}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corss_7 54.05833333333334\n",
      "cross_without_sf 14.0\n",
      "cross_without_bot 12.15\n",
      "cross_without_sf_el 66.61666666666666\n",
      "cross_without_bot_el 55.15\n"
     ]
    }
   ],
   "source": [
    "dataframes[\"corss_7\"] = df\n",
    "dataframes[\"cross_without_sf\"] = df[(df.repository != \"spring-framework\")]\n",
    "dataframes[\"cross_without_bot\"] = df[(df.repository != \"spring-framework\") & (df.repository != \"guava\")]\n",
    "dataframes[\"cross_without_sf_el\"] = df[(df.repository != \"spring-framework\") & (df.repository != \"elasticsearch\")]\n",
    "dataframes[\"cross_without_bot_el\"] =  df[(df.repository != \"spring-framework\") & (df.repository != \"guava\") & (df.repository != \"elasticsearch\")]\n",
    "\n",
    "for repo in corss_repos:\n",
    "    reaction_time_med[repo] = dataframes[repo].reaction_time.median()\n",
    "    print(repo, reaction_time_med[repo])\n",
    "    dataframes[repo].to_csv(f\"../data/repos/final/{repo}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "nontext_columns = [    \n",
    "    'is_pull_request',\n",
    "    'title_len',\n",
    "    'body_len',\n",
    "    'num_comments',\n",
    "    'num_events',\n",
    "    'author_followers',\n",
    "    'closer_followers',\n",
    "    'author_following',\n",
    "    'closer_following',\n",
    "    'author_public_repos',\n",
    "    'closer_public_repos',\n",
    "    'author_public_gists',\n",
    "    'closer_public_gists',\n",
    "    'author_core_team',\n",
    "    'author_has_association',\n",
    "    'author_issue_counts',\n",
    "    'commits_count',\n",
    "    'has_commit',\n",
    "    'cm_developers_number',\n",
    "    'cm_developers_ratio',\n",
    "    'cm_developers_unique',\n",
    "    'cm_authors_unique',\n",
    "    'cm_developers_ratio_unique',\n",
    "    'cm_mean_len',\n",
    "    'time_to_discuss',\n",
    "    'author_github_cntrb',\n",
    "    'closer_github_cntrb',\n",
    "    'author_repo_cntrb',\n",
    "    'closer_repo_cntrb',\n",
    "    'title_words_num',\n",
    "    'body_words_num',   \n",
    "    'title_alpha_len',\n",
    "    'title_alphabet_ratio',\n",
    "    'body_alpha_len',\n",
    "    'body_alphabet_ratio',\n",
    "    'body_processed_len',\n",
    "    'title_processed_len',\n",
    "    'title_processed_words_num',\n",
    "    'body_processed_words_num',\n",
    "    'num_of_sharps',\n",
    "    'num_of_at',\n",
    "    'num_of_qmark',\n",
    "    'num_of_codesnippets',\n",
    "    'num_of_functions',\n",
    "    'num_of_issues',\n",
    "    'num_of_paths',\n",
    "    'num_of_dates',\n",
    "    'num_of_times',\n",
    "    'num_of_urls',\n",
    "    'num_of_emails',\n",
    "    'num_of_obligations',\n",
    "    'has_email',\n",
    "    'has_code',\n",
    "    'ft_bug',\n",
    "    'ft_feature',\n",
    "    'ft_other',    \n",
    "    'title_sentistrenght_p',\n",
    "    'body_sentistrenght_p',\n",
    "    'title_subjectivity',\n",
    "    'body_subjectivity',\n",
    "    'positive_body_sentistrenght_n',\n",
    "    'positive_title_sentistrenght_n',\n",
    "    'positive_title_polarity',\n",
    "    'positive_body_polarity',\n",
    "    'author_account_age',\n",
    "    'closer_account_age',\n",
    "    'has_assignee',\n",
    "    'num_of_assignees',\n",
    "    'has_milestone',\n",
    "    'numeric_association'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticsearch\n",
      "spring-framework\n",
      "spring-boot\n",
      "okhttp\n",
      "RxJava\n",
      "guava\n",
      "retrofit\n",
      "corss_7\n",
      "cross_without_sf\n",
      "cross_without_bot\n",
      "cross_without_sf_el\n",
      "cross_without_bot_el\n"
     ]
    }
   ],
   "source": [
    "for repo in repos:\n",
    "    print(repo)\n",
    "    df = dataframes[repo]\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state = 42, shuffle=True)\n",
    "    train[\"test_tag\"] = 0\n",
    "    test[\"test_tag\"] = 1\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    train[nontext_columns]  = min_max_scaler.fit_transform(train[nontext_columns])\n",
    "    test[nontext_columns]  = min_max_scaler.transform(test[nontext_columns])\n",
    "    df = pd.concat([train, test], ignore_index=True)\n",
    "    \n",
    "    df[\"priority\"] = df.reaction_time.apply(lambda x: 2 if x<=reaction_time_med[repo] else 1 if x>reaction_time_med[repo] else 0)\n",
    "    if repo in corss_repos:\n",
    "        df[\"priority_per_repo\"] = df.apply(lambda r: 2 if r.reaction_time<=reaction_time_med[r.repository] else 1 if r.reaction_time>reaction_time_med[r.repository] else 0, axis = 1)\n",
    "    \n",
    "    df.to_csv(f\"../data/repos/final/{repo}_norm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
