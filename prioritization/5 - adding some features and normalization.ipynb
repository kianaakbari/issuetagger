{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1- Adding fasttext probs and sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/repos/3/allrepos_processed.csv\")\n",
    "senti = pd.read_csv(\"../data/repos/3/allrepos_sentiments.csv\")\n",
    "ftprobs = pd.read_csv(\"../data/repos/3/allrepos_ftprobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ft_bug\"] = ftprobs[\"__label__bug\"] \n",
    "df[\"ft_feature\"] = ftprobs[\"__label__feature\"] \n",
    "df[\"ft_other\"] = ftprobs[\"__label__other\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_sentistrenght_p\"] = senti[\"title_sentistrenght\"].apply(lambda x: x.split(',')[0])\n",
    "df[\"title_sentistrenght_n\"] = senti[\"title_sentistrenght\"].apply(lambda x: x.split(',')[1])\n",
    "\n",
    "df[\"body_sentistrenght_p\"] = senti[\"body_sentistrenght\"].apply(lambda x: x.split(',')[0])\n",
    "df[\"body_sentistrenght_n\"] = senti[\"body_sentistrenght\"].apply(lambda x: x.split(',')[1])\n",
    "\n",
    "df[\"title_polarity\"] = senti[\"title_textblob\"].apply(lambda x: x.split(',')[0])\n",
    "df[\"title_subjectivity\"] = senti[\"title_textblob\"].apply(lambda x: x.split(',')[1])\n",
    "\n",
    "df[\"body_polarity\"] = senti[\"body_textblob\"].apply(lambda x: x.split(',')[0])\n",
    "df[\"body_subjectivity\"] = senti[\"body_textblob\"].apply(lambda x: x.split(',')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"positive_title_sentistrenght_n\"] = df[\"title_sentistrenght_n\"].astype(int).abs()\n",
    "df[\"positive_body_sentistrenght_n\"] = df[\"body_sentistrenght_n\"].astype(int).abs()\n",
    "df[\"positive_title_polarity\"] = df[\"title_polarity\"].astype(float) + 1\n",
    "df[\"positive_body_polarity\"] = df[\"body_polarity\"].astype(float) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2- Applynig some other preprocessings and adding some columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df.closer_login.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_time_interval(t1, t2):\n",
    "    d1 = datetime.strptime(t1, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    d2 = datetime.strptime(t2, \"%Y-%m-%dT%H:%M:%SZ\")\n",
    "    delta = d2-d1\n",
    "    return delta.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_time = df.created_at.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"author_account_age\"] = df[\"author_created_at\"].apply(lambda x: round(compute_time_interval(x, base_time)/365))    \n",
    "df[\"closer_account_age\"] = df[\"closer_created_at\"].apply(lambda x: round(compute_time_interval(x, base_time)/365))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"has_assignee\"] = ~df[\"assignee\"].isna()\n",
    "df[\"num_of_assignees\"] = df[\"assignees\"].apply(lambda x: 0 if pd.isna(x) else len(x.split(\"|\")))\n",
    "df['has_milestone'] = df['milestone'].apply(lambda x: 0 if pd.isna(x) else 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"author_github_cntrb\"] = df[\"author_github_cntrb\"].apply(lambda x: int(str(x).replace(',','')))\n",
    "df[\"closer_github_cntrb\"] = df[\"closer_github_cntrb\"].apply(lambda x: int(str(x).replace(',','')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['numeric_association'] = df['author_association'].apply(lambda x: 0 if x == \"NONE\"  else 1 if x == \"CONTRIBUTOR\" else 2 if x == \"MEMBER\" else 3 if x == \"OWNER\" else 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df[(df.repository == \"spring-framework\") & (df.author_login == \"spring-issuemaster\")].shape)\n",
    "# print(df[(df.repository == \"spring-framework\") & (df.author_login != \"spring-issuemaster\")].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df[(df.repository == \"spring-framework\") & (df.closer_login == \"spring-issuemaster\")].shape)\n",
    "# print(df[(df.repository == \"spring-framework\") & (df.closer_login != \"spring-issuemaster\")].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df[(df.repository == \"spring-framework\") & (df.author_login == \"spring-issuemaster\") & (df.closer_login == \"spring-issuemaster\")].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"author_creation_day_before_issue\"] = df.apply(lambda x: np.nan if x.author_login == \"spring-issuemaster\" else compute_time_interval(x.author_created_at, x.created_at) ,axis=1)\n",
    "# df[\"tyro_author\"] = df[\"author_creation_day_before_issue\"].apply(lambda x: 1 if x<5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "spring-framework has a spring-issuemaster author which owns 17005 issues form total 19719 issues!!\n",
    "this user also closed 16900 issues of spring-framework and 230 issues from spring-boot\n",
    "spring-issuemaster doesnt have any repo and star, thus considering author info for spring-framework repo is meaningless\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.columns[df.isna().any()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22019, 112)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.reaction_time.isna()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {}\n",
    "dataframes[\"elasticsearch\"] =  df[df.repository == \"elasticsearch\"]\n",
    "dataframes[\"spring-boot\"] =  df[(df.repository == \"spring-boot\") & (df.closer_login != \"spring-issuemaster\")]\n",
    "dataframes[\"spring-framework\"] =  df[(df.repository == \"spring-framework\") & (df.author_login == \"spring-issuemaster\") & (df.closer_login == \"spring-issuemaster\")]\n",
    "dataframes[\"cross-project\"] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = list(dataframes.keys())\n",
    "for repo in repos:\n",
    "    dataframes[repo].to_csv(f\"../data/repos/final/{repo}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for repo in [\"elasticsearch\", \"spring-boot\", \"spring-framework\", \"cross-project\"]:\n",
    "#     df = pd.read_csv(f\"../data/repos/final/{repo}.csv\")\n",
    "#     print(repo, df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16876+15025+44099"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3- Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "nontext_columns = [    \n",
    "    'is_pull_request',\n",
    "    'title_len',\n",
    "    'body_len',\n",
    "    'num_comments',\n",
    "    'num_events',\n",
    "    'author_followers',\n",
    "    'closer_followers',\n",
    "    'author_following',\n",
    "    'closer_following',\n",
    "    'author_public_repos',\n",
    "    'closer_public_repos',\n",
    "    'author_public_gists',\n",
    "    'closer_public_gists',\n",
    "    'author_core_team',\n",
    "    'author_has_association',\n",
    "    'author_issue_counts',\n",
    "    'commits_count',\n",
    "    'has_commit',\n",
    "    'cm_developers_number',\n",
    "    'cm_developers_ratio',\n",
    "    'cm_developers_unique',\n",
    "    'cm_authors_unique',\n",
    "    'cm_developers_ratio_unique',\n",
    "    'cm_mean_len',\n",
    "    'time_to_discuss',\n",
    "    'author_github_cntrb',\n",
    "    'closer_github_cntrb',\n",
    "    'author_repo_cntrb',\n",
    "    'closer_repo_cntrb',\n",
    "    'title_words_num',\n",
    "    'body_words_num',   \n",
    "    'title_alpha_len',\n",
    "    'title_alphabet_ratio',\n",
    "    'body_alpha_len',\n",
    "    'body_alphabet_ratio',\n",
    "    'body_processed_len',\n",
    "    'title_processed_len',\n",
    "    'title_processed_words_num',\n",
    "    'body_processed_words_num',\n",
    "    'num_of_sharps',\n",
    "    'num_of_at',\n",
    "    'num_of_qmark',\n",
    "    'num_of_codesnippets',\n",
    "    'num_of_functions',\n",
    "    'num_of_issues',\n",
    "    'num_of_paths',\n",
    "    'num_of_dates',\n",
    "    'num_of_times',\n",
    "    'num_of_urls',\n",
    "    'num_of_emails',\n",
    "    'num_of_obligations',\n",
    "    'has_email',\n",
    "    'has_code',\n",
    "    'ft_bug',\n",
    "    'ft_feature',\n",
    "    'ft_other',    \n",
    "    'title_sentistrenght_p',\n",
    "    'body_sentistrenght_p',\n",
    "    'title_subjectivity',\n",
    "    'body_subjectivity',\n",
    "    'positive_body_sentistrenght_n',\n",
    "    'positive_title_sentistrenght_n',\n",
    "    'positive_title_polarity',\n",
    "    'positive_body_polarity',\n",
    "    'author_account_age',\n",
    "    'closer_account_age',\n",
    "    'has_assignee',\n",
    "    'num_of_assignees',\n",
    "    'has_milestone',\n",
    "    'numeric_association'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elasticsearch\n",
      "spring-boot\n",
      "spring-framework\n",
      "cross-project\n"
     ]
    }
   ],
   "source": [
    "for repo in repos:\n",
    "    print(repo)\n",
    "    df = dataframes[repo]\n",
    "    train, test = train_test_split(df, test_size=0.2, random_state = 42, shuffle=True)\n",
    "    train[\"test_tag\"] = 0\n",
    "    test[\"test_tag\"] = 1\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    train[nontext_columns]  = min_max_scaler.fit_transform(train[nontext_columns])\n",
    "    test[nontext_columns]  = min_max_scaler.transform(test[nontext_columns])\n",
    "    df = pd.concat([train, test], ignore_index=True)\n",
    "    df.to_csv(f\"../data/repos/final/{repo}_norm.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
