{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import _pickle as cPickle\n",
    "from datetime import datetime\n",
    "import time\n",
    "from itertools import product \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from scipy.stats import uniform\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = ['balanced', None]\n",
    "# class_weight = [None]\n",
    "\n",
    "n_jobs = 1\n",
    "random_state = 42\n",
    "\n",
    "rf_random_grid = {'bootstrap': [True, False],\n",
    "                  'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "                  'max_features': ['auto', 'log2', None],\n",
    "                  'min_samples_leaf': [1, 2, 4],\n",
    "                  'min_samples_split': [2, 5, 10],\n",
    "                  'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
    "                  'class_weight': class_weight+[\"balanced_subsample\"]}\n",
    "\n",
    "svc_random_grid = {'C': np.logspace(-3, 2, 6), \n",
    "                   'gamma': ['auto', 'scale'],\n",
    "                   'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                   'class_weight' : class_weight}\n",
    "\n",
    "sgd_random_grid = {\"loss\": [\"hinge\", \"log\", \"modified_huber\", \"squared_hinge\", \"perceptron\"],\n",
    "                   \"penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
    "                   \"l1_ratio\": 0.2*np.arange(0,6),\n",
    "                   'class_weight' : class_weight}\n",
    "\n",
    "knn_random_grid = {\"leaf_size\" : list(range(1,50)),\n",
    "                   \"n_neighbors\" : list(range(1,35)),\n",
    "                   \"p\": [1,2]}\n",
    "\n",
    "lr_random_grid = {'C' : np.logspace(-3, 2, 6),\n",
    "                  'penalty' : ['l2', 'none'],\n",
    "                  'solver' : ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "                  'class_weight' : class_weight}\n",
    "\n",
    "# lr_random_grid_2 = {'C' : np.logspace(-3, 2, 6),\n",
    "#                   'penalty' : ['l1', 'l2'],\n",
    "#                   'solver' : ['saga', 'liblinear'],\n",
    "#                   'class_weight' : class_weight}\n",
    "\n",
    "classifiers = {\n",
    "    \"mnb\" : {\"clf\" : MultinomialNB()},\n",
    "    \"gnb\" : {\"clf\" : GaussianNB()},\n",
    "    \"lr\" : {\"clf\" : LogisticRegression(n_jobs=n_jobs, random_state=random_state), \"random_grid\" : lr_random_grid, \"clf_with_params\" : LogisticRegression(n_jobs=n_jobs, random_state=random_state)},\n",
    "    \"sgd\" : {\"clf\" : SGDClassifier(n_jobs=n_jobs, random_state=random_state), \"random_grid\" : sgd_random_grid, \"clf_with_params\" : SGDClassifier(n_jobs=n_jobs, random_state=random_state)},\n",
    "    \"svc\" : {\"clf\" : SVC(random_state=random_state), \"random_grid\" : svc_random_grid, \"clf_with_params\" : SVC(random_state=random_state)},    \n",
    "    \"rf\" : {\"clf\" : RandomForestClassifier(n_jobs=n_jobs, random_state=random_state), \"random_grid\" : rf_random_grid, \"clf_with_params\" : RandomForestClassifier(n_jobs=n_jobs, random_state=random_state)},\n",
    "    \"knn\" : {\"clf\" : KNeighborsClassifier(n_jobs=n_jobs), \"random_grid\" : knn_random_grid, \"clf_with_params\" : KNeighborsClassifier(n_jobs=n_jobs)}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "issue_features = [    \n",
    "    \n",
    "    'num_comments', 'num_events', 'commits_count', 'is_pull_request', 'num_of_assignees', 'has_milestone',\n",
    "    \n",
    "    'cm_mean_len', 'time_to_discuss', 'cm_developers_ratio',\n",
    "    \n",
    "    'body_processed_len', 'title_processed_len', 'title_processed_words_num', 'body_processed_words_num', \n",
    "    'title_alphabet_ratio', 'body_alphabet_ratio',\n",
    "    \n",
    "    'num_of_codesnippets',\n",
    "    'num_of_functions',\n",
    "    'num_of_issues',\n",
    "    'num_of_paths',\n",
    "    'num_of_urls',\n",
    "\n",
    "    \n",
    "    'ft_bug',\n",
    "    'ft_feature',   \n",
    "    \n",
    "    'body_sentistrenght_p',\n",
    "    'title_subjectivity',\n",
    "    'body_subjectivity',\n",
    "    'positive_body_sentistrenght_n',\n",
    "    'positive_title_polarity',\n",
    "    'positive_body_polarity',\n",
    "]\n",
    "    \n",
    "user_features = [\n",
    "    'author_followers', 'author_following', 'author_public_repos', 'author_public_gists', 'author_issue_counts', \n",
    "    'author_github_cntrb', 'author_repo_cntrb', 'author_account_age', 'numeric_association'\n",
    "]\n",
    "\n",
    "all_features = issue_features + user_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(dataset, algorithm=\"rf\", param_mode=\"default\", target_column=\"priority\", save_importances=True):    \n",
    "    \n",
    "#     if dataset == \"spring-framework\":\n",
    "#         features = issue_features\n",
    "#     else:\n",
    "#         features = all_features\n",
    "        \n",
    "    df = dataframes[dataset]\n",
    "    \n",
    "    X_train = df[df.test_tag == 0][all_features]\n",
    "    X_test = df[df.test_tag == 1][all_features]\n",
    "    y_train = df[df.test_tag == 0][target_column]\n",
    "    y_test = df[df.test_tag == 1][target_column]\n",
    "\n",
    "    title = f\"{dataset}_{param_mode}_{algorithm}_{target_column}\"    \n",
    "    report = title + \":\\n\"\n",
    "\n",
    "    if param_mode == \"default\":\n",
    "        model = classifiers[algorithm][\"clf\"]\n",
    "    elif param_mode == \"specified\":\n",
    "        model = classifiers[algorithm][\"clf_with_params\"]\n",
    "    elif param_mode == \"tuned\":\n",
    "        model = RandomizedSearchCV(estimator=classifiers[algorithm][\"clf\"], param_distributions = classifiers[algorithm][\"random_grid\"], \n",
    "                               n_iter=100, cv=3, random_state=42, n_jobs=-1)\n",
    "        \n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report += classification_report(y_test, y_pred)\n",
    "    if(param_mode == \"tuned\"):\n",
    "        report += \"\\nbestparameters:\\n\" + str(model.best_params_) + '\\n'\n",
    "    accuracy = accuracy_score(y_pred, y_test)\n",
    "    report += \"\\naccuracy score:\" + str(accuracy) + '\\n'\n",
    "    with open(f\"results/{title}.txt\", \"w\") as f:\n",
    "        f.write(report)\n",
    "    print(report)\n",
    "\n",
    "    if algorithm == \"rf\" and save_importances:\n",
    "        nfeatures  = X_test.shape[1]\n",
    "        fig, ax = plt.subplots(dpi=300, figsize = [20,15])\n",
    "        ax.barh(range(nfeatures), model.feature_importances_)\n",
    "        ax.set_yticks(range(nfeatures))\n",
    "        ax.set_yticklabels(all_features)\n",
    "        fig.savefig(f\"results/images/{title}\")\n",
    "#         fig.savefig(f\"results/images/{title}.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_repos = ['elasticsearch', 'spring-framework', 'spring-boot', 'okhttp', 'RxJava', 'guava', 'retrofit']\n",
    "corss_repos = [\"corss_7\", \"cross_without_sf\", \"cross_without_bot\", \"cross_without_sf_el\", \"cross_without_bot_el\"]\n",
    "dataframes = {}\n",
    "for repo in base_repos+corss_repos:\n",
    "    dataframes[repo] = pd.read_csv(f\"../data/repos/final/{repo}_norm.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = \"rf\"\n",
    "param_mode = \"default\"     #param_modes = [\"defualt\", \"tuned\", \"specified\"]\n",
    "target_column = \"priority\"     #columns = [\"priority\", \"priority_per_repo\"]  \n",
    "save_importances = False\n",
    "\n",
    "for repo in base_repos + corss_repos:\n",
    "    classify(repo, algorithm, param_mode, target_column, save_importances)\n",
    "    \n",
    "target_column = \"priority_per_repo\"\n",
    "for repo in corss_repos:\n",
    "    classify(repo, algorithm, param_mode, target_column, save_importances)\n",
    "    \n",
    "print(\"********done********\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #unnorm\n",
    "# dataset = \"cross-project\"\n",
    "# df = pd.read_csv(f\"../data/repos/final/{dataset}.csv\")\n",
    "# reaction_time_med = df.reaction_time.median()\n",
    "\n",
    "# df[\"priority\"] = df.reaction_time.apply(lambda x: 2 if x<=reaction_time_med else 1 if x>reaction_time_med else 0)\n",
    "\n",
    "# y = df.priority\n",
    "# x = df[all_features]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state = 42, shuffle=True)\n",
    "\n",
    "# title = f\"{dataset} + {algorithm}\"    \n",
    "# report = title + \":\\n\"\n",
    "\n",
    "# model = RandomForestClassifier(n_jobs=n_jobs, random_state=random_state, n_estimators=1000, min_samples_split=10, min_samples_leaf=2, max_features='auto', max_depth=100, class_weight='balanced', bootstrap=False)\n",
    "\n",
    "# model.fit(X_train, y_train)\n",
    "# y_pred = model.predict(X_test)\n",
    "# report += classification_report(y_test, y_pred)\n",
    "# accuracy = accuracy_score(y_pred, y_test)\n",
    "# report += \"\\naccuracy score:\" + str(accuracy) + '\\n'\n",
    "# print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"../data/repos/final/cross-project.csv\")\n",
    "# df = df[~df.reaction_time.isna()]\n",
    "\n",
    "# y = df.reaction_time\n",
    "# x = df[all_features]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state = 42, shuffle=True)\n",
    "\n",
    "# # X_train = df[df.test_tag == 0][all_features]\n",
    "# # X_test = df[df.test_tag == 1][all_features]\n",
    "# # y_train = df[df.test_tag == 0].reaction_time\n",
    "# # y_test = df[df.test_tag == 1].reaction_time\n",
    "\n",
    "# algorithm = \"rf\"\n",
    "# RandomizedSearchCV(estimator=RandomForestRegressor(), param_distributions = classifiers[algorithm][\"random_grid\"], \n",
    "#                                    n_iter=100, cv=3 , random_state=42, n_jobs=4)\n",
    "# model.fit(X_train, y_train)\n",
    "# model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# issue_features_total = [    \n",
    "    \n",
    "#     'num_comments', 'num_events', 'commits_count', 'is_pull_request', 'num_of_assignees', 'has_milestone',\n",
    "    \n",
    "#     'cm_mean_len', 'time_to_discuss', 'cm_developers_ratio',\n",
    "    \n",
    "#     'body_processed_len', 'title_processed_len', 'title_processed_words_num', 'body_processed_words_num', \n",
    "#     'title_alphabet_ratio', 'body_alphabet_ratio',\n",
    "    \n",
    "#     'num_of_qmark',\n",
    "#     'num_of_codesnippets',\n",
    "#     'num_of_functions',\n",
    "#     'num_of_issues',\n",
    "#     'num_of_paths',\n",
    "#     'num_of_dates',\n",
    "#     'num_of_times',\n",
    "#     'num_of_urls',\n",
    "#     'num_of_sharps',\n",
    "#     'num_of_at',\n",
    "#     'num_of_emails',\n",
    "#     'num_of_obligations',\n",
    "    \n",
    "#     'ft_bug',\n",
    "#     'ft_feature',   \n",
    "    \n",
    "#     'title_sentistrenght_p',\n",
    "#     'body_sentistrenght_p',\n",
    "#     'title_subjectivity',\n",
    "#     'body_subjectivity',\n",
    "#     'positive_body_sentistrenght_n',\n",
    "#     'positive_title_sentistrenght_n',\n",
    "#     'positive_title_polarity',\n",
    "#     'positive_body_polarity',\n",
    "# ]\n",
    "\n",
    "# issue_features_2 = [    \n",
    "    \n",
    "#     'num_comments', 'num_events', 'commits_count', 'is_pull_request', 'num_of_assignees', 'has_milestone',\n",
    "    \n",
    "#     'cm_mean_len', 'time_to_discuss', 'cm_developers_ratio',\n",
    "    \n",
    "#     'body_processed_len', 'title_processed_len', 'title_processed_words_num', 'body_processed_words_num', \n",
    "#     'title_alphabet_ratio', 'body_alphabet_ratio',\n",
    "    \n",
    "#     'num_of_codesnippets',\n",
    "#     'num_of_urls',\n",
    "    \n",
    "#     'ft_bug',\n",
    "#     'ft_feature',   \n",
    "    \n",
    "#     'body_sentistrenght_p',\n",
    "#     'body_subjectivity',\n",
    "#     'positive_body_sentistrenght_n',\n",
    "#     'positive_body_polarity',\n",
    "# ]\n",
    "\n",
    "# user_features_total = [\n",
    "#     'author_followers', 'closer_followers', 'author_following', 'closer_following', 'author_public_repos', 'closer_public_repos', \n",
    "#     'author_public_gists', 'closer_public_gists', 'author_issue_counts',\n",
    "#     'author_github_cntrb', 'closer_github_cntrb', 'author_repo_cntrb', 'closer_repo_cntrb', 'author_account_age',\n",
    "#     'closer_account_age', 'numeric_association'\n",
    "# ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
