{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/clean_mono_norm.csv\")\n",
    "senti = pd.read_csv(\"data/sentiments.csv\")\n",
    "ftprobs = pd.read_csv(\"data/cleanlabels_ftprobs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"ft_bug\"] = ftprobs[\"__label__bug\"] \n",
    "df[\"ft_feature\"] = ftprobs[\"__label__feature\"] \n",
    "df[\"ft_other\"] = ftprobs[\"__label__other\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"title_sentistrenght_p\"] = senti[\"title_sentistrenght\"].apply(lambda x: x.split(',')[0])\n",
    "df[\"title_sentistrenght_n\"] = senti[\"title_sentistrenght\"].apply(lambda x: x.split(',')[1])\n",
    "\n",
    "df[\"body_sentistrenght_p\"] = senti[\"body_sentistrenght\"].apply(lambda x: x.split(',')[0])\n",
    "df[\"body_sentistrenght_n\"] = senti[\"body_sentistrenght\"].apply(lambda x: x.split(',')[1])\n",
    "\n",
    "df[\"title_polarity\"] = senti[\"title_textblob\"].apply(lambda x: x.split(',')[0])\n",
    "df[\"title_subjectivity\"] = senti[\"title_textblob\"].apply(lambda x: x.split(',')[1])\n",
    "\n",
    "df[\"body_polarity\"] = senti[\"body_textblob\"].apply(lambda x: x.split(',')[0])\n",
    "df[\"body_subjectivity\"] = senti[\"body_textblob\"].apply(lambda x: x.split(',')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"positive_title_sentistrenght_n\"] = df[\"title_sentistrenght_n\"].astype(int).abs()\n",
    "df[\"positive_body_sentistrenght_n\"] = df[\"body_sentistrenght_n\"].astype(int).abs()\n",
    "df[\"positive_title_polarity\"] = df[\"title_polarity\"].astype(float) + 1\n",
    "df[\"positive_body_polarity\"] = df[\"body_polarity\"].astype(float) + 1\n",
    "df['num_of_qmark'] = df['num_of_qmark'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/final_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_columns = ['number', 'repository_url', 'title', 'body', 'title_processed', 'body_processed', \n",
    "                   'title_proc_lem', 'body_proc_lem', 'label_cat', 'test_tag']\n",
    "\n",
    "df[df_text_columns].to_csv(\"data/finaldf_text_columns.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['title', 'body', 'title_processed', 'body_processed', \n",
    "                   'title_proc_lem', 'body_proc_lem'], inplace=True)\n",
    "\n",
    "df.to_csv(\"data/finaldf_nontext_columns.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"data/finaldf_nontext_columns.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[df.test_tag==0]\n",
    "test = df[df.test_tag==1]\n",
    "\n",
    "unnormalized_columns = ['comments', 'num_of_assignees',\n",
    "                        'reaction_total_count', 'reaction_+1', 'reaction_-1', 'reaction_laugh', 'reaction_hooray', 'reaction_confused', 'reaction_heart', 'reaction_rocket', 'reaction_eyes', \n",
    "                        'title_len', 'body_len', 'title_words_num', 'body_words_num', 'title_alpha_len', 'body_alpha_len', \n",
    "                        'body_processed_len', 'title_processed_len', 'title_processed_words_num', 'body_processed_words_num',\n",
    "                        'title_lem_len', 'title_lem_words_num', 'body_lem_len', 'body_lem_words_num',\n",
    "                        'num_of_sharps', 'num_of_at', 'num_of_qmark', 'num_of_codesnippets', 'num_of_functions', 'num_of_issues', 'num_of_paths', 'num_of_dates', 'num_of_times', 'num_of_urls', 'num_of_emails', 'num_of_obligations',\n",
    "                        'title_sentistrenght_p', 'positive_title_sentistrenght_n', 'body_sentistrenght_p', 'positive_body_sentistrenght_n',\n",
    "                        'positive_title_polarity', 'positive_body_polarity']\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "train[unnormalized_columns]  = min_max_scaler.fit_transform(train[unnormalized_columns])\n",
    "test[unnormalized_columns]  = min_max_scaler.transform(test[unnormalized_columns])\n",
    "\n",
    "norm_df = pd.concat([train, test], ignore_index=True)\n",
    "norm_df.to_csv(\"data/normdf_nontext_columns.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
