{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import _pickle as cPickle\n",
    "from datetime import datetime\n",
    "import time\n",
    "from itertools import product \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from scipy.stats import uniform\n",
    "from datetime import datetime\n",
    "\n",
    "def get_features(mode, file_postfix):\n",
    "        \n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    \n",
    "    if mode == \"d2v\" or mode == \"tfidf\":  \n",
    "    \n",
    "        vectors = {}\n",
    "        train_other_features = df[df.test_tag == 0][common_columns]\n",
    "        test_other_features = df[df.test_tag == 1][common_columns]\n",
    "        \n",
    "        for section, column in product([\"train\", \"test\"], [\"title\", \"body\"]):\n",
    "            with open(f\"data/vectors/{mode}_{file_postfix}_{section}_{column}\", 'rb') as f:\n",
    "                vectors[f\"{section}_{column}\"] = cPickle.load(f)\n",
    "    \n",
    "        if mode == \"d2v\":\n",
    "            x_train = np.append(vectors[\"train_title\"], vectors[\"train_body\"], axis=1)\n",
    "            x_test = np.append(vectors[\"test_title\"], vectors[\"test_body\"], axis=1)\n",
    "        elif mode == \"tfidf\":\n",
    "            x_train = sparse.hstack((vectors[\"train_title\"],vectors[\"train_body\"]))\n",
    "            x_test = sparse.hstack((vectors[\"test_title\"],vectors[\"test_body\"]))\n",
    "        \n",
    "    elif feature_mode == \"ft2stage\":\n",
    "        x_train = df[df.test_tag == 0][common_columns+ft_columns]\n",
    "        x_test = df[df.test_tag == 1][common_columns+ft_columns]\n",
    "        \n",
    "    return x_train, x_test\n",
    "\n",
    "\n",
    "\n",
    "n_jobs = 1\n",
    "random_state = 42\n",
    "\n",
    "classifiers = {\n",
    "    \"mnb\" : {\"clf\" : MultinomialNB()},\n",
    "    \"gnb\" : {\"clf\" : GaussianNB()},\n",
    "    \"lr\" : {\"clf\" : LogisticRegression(random_state=random_state)},\n",
    "    \"sgd\" : {\"clf\" : SGDClassifier(random_state=random_state)},\n",
    "    \"svc\" : {\"clf\" : SVC(random_state=random_state)},    \n",
    "    \"rf\" : {\"clf\" : RandomForestClassifier(n_jobs=n_jobs, random_state=random_state)},\n",
    "    \"knn\" : {\"clf\" : KNeighborsClassifier(n_jobs=n_jobs)}\n",
    "}\n",
    "\n",
    "common_columns = [\n",
    " 'comments', 'is_pull_request', 'has_milestone', 'num_of_assignees', 'reaction_total_count', 'numeric_association',\n",
    "\n",
    " 'num_of_sharps',\n",
    " 'num_of_at',\n",
    " 'num_of_codesnippets',\n",
    " 'num_of_functions',\n",
    " 'num_of_issues',\n",
    " 'num_of_paths',\n",
    " 'num_of_dates',\n",
    " 'num_of_times',\n",
    " 'num_of_urls',\n",
    " 'num_of_emails',\n",
    " 'num_of_obligations',\n",
    " 'num_of_qmark',\n",
    " \n",
    " 'title_lem_len',\n",
    " 'title_lem_words_num',\n",
    " 'body_lem_len',\n",
    " 'body_lem_words_num',\n",
    " 'title_alphabet_ratio',\n",
    " 'body_alphabet_ratio',\n",
    " \n",
    " 'title_sentistrenght_p',\n",
    " 'body_sentistrenght_p',\n",
    " 'title_subjectivity',\n",
    " 'body_subjectivity',\n",
    " 'positive_body_sentistrenght_n',\n",
    " 'positive_title_sentistrenght_n',\n",
    " 'positive_title_polarity',\n",
    " 'positive_body_polarity']\n",
    "\n",
    "\n",
    "ft_columns = ['ft_bug', 'ft_feature']\n",
    "file_postfix = {\"tfidf\": \"processed\", \"d2v\": \"500-500_proc-lem\", \"ft2stage\": \"\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"normdf_nontext_columns\"\n",
    "df = pd.read_csv(f\"data/{dataset_name}.csv\")\n",
    "feature_mode = \"tfidf\"\n",
    "y_train = df[df.test_tag == 0].label_cat\n",
    "y_test = df[df.test_tag == 1].label_cat\n",
    "x_train, x_test = get_features(feature_mode, file_postfix=file_postfix[feature_mode])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [('sgd', SGDClassifier(penalty='l2', loss='modified_huber', l1_ratio=0.0, class_weight=None, random_state=random_state, n_jobs = n_jobs)), \n",
    "              ('lr', LogisticRegression(solver='sag', penalty='l2', class_weight=None, C=1.0, random_state=random_state, n_jobs = n_jobs)), \n",
    "              ('svc', SVC(kernel='rbf', gamma='scale', class_weight=None, C=1.0, probability=True, random_state=random_state))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(ensemble_method, voting_strategy = \"soft\", final_estimator = \"lr\"):\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "\n",
    "    title = f\"{ensemble_method} {voting_strategy}\" if ensemble_method == \"voting\" else f\"{ensemble_method} {final_estimator}\"    \n",
    "    report = title.strip() + \":\\n\"\n",
    "    \n",
    "    if ensemble_method == \"voting\":\n",
    "        model = VotingClassifier(estimators, voting = voting_strategy, n_jobs=n_jobs)\n",
    "    elif ensemble_method == \"stacking\":\n",
    "        model = StackingClassifier(estimators=estimators, final_estimator=classifiers[final_estimator][\"clf\"], n_jobs=n_jobs)\n",
    "  \n",
    "    y_pred = [] \n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)   \n",
    "    report += classification_report(y_test, y_pred)\n",
    "    \n",
    "    \n",
    "    report += \"\\nscore:\\n\" + str(model.score()) + '\\n'\n",
    "    \n",
    "#     scores = cross_val_score(model, x, y, cv=10, scoring='accuracy', n_jobs=38)\n",
    "#     print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "        \n",
    "    accuracyScore = accuracy_score(y_pred, y_test)\n",
    "    report += \"\\naccuracy score:\" + str(accuracyScore) + '\\n'\n",
    "    \n",
    "    report += \"\\n\\nduration: \" + str(datetime.now() - start_time)\n",
    "    \n",
    "    print(report)   \n",
    "    \n",
    "    with open(f\"results/{title}_fs2.txt\", \"w\") as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    print(\"duration: \" + str(datetime.now() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify(\"voting\", \"soft\")\n",
    "print(\"******************done******************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
