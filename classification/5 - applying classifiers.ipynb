{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy\n",
    "from scipy import sparse\n",
    "import _pickle as cPickle\n",
    "from datetime import datetime\n",
    "import time\n",
    "from itertools import product \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from scipy.stats import uniform\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(mode, file_postfix):\n",
    "        \n",
    "    x_train = []\n",
    "    x_test = []\n",
    "    \n",
    "    if mode == \"d2v\" or mode == \"tfidf\":  \n",
    "    \n",
    "        vectors = {}\n",
    "        train_other_features = df[df.test_tag == 0][common_columns]\n",
    "        test_other_features = df[df.test_tag == 1][common_columns]\n",
    "        \n",
    "        for section, column in product([\"train\", \"test\"], [\"title\", \"body\"]):\n",
    "            with open(f\"data/vectors/{mode}_{file_postfix}_{section}_{column}\", 'rb') as f:\n",
    "                vectors[f\"{section}_{column}\"] = cPickle.load(f)\n",
    "    \n",
    "        if mode == \"d2v\":\n",
    "            x_train = np.append(vectors[\"train_title\"], np.append(vectors[\"train_body\"], train_other_features ,axis=1), axis=1)\n",
    "            x_test = np.append(vectors[\"test_title\"], np.append(vectors[\"test_body\"], test_other_features ,axis=1), axis=1)\n",
    "        elif mode == \"tfidf\":\n",
    "            x_train = sparse.hstack((vectors[\"train_title\"],vectors[\"train_body\"],train_other_features))\n",
    "            x_test = sparse.hstack((vectors[\"test_title\"],vectors[\"test_body\"],test_other_features))\n",
    "        \n",
    "    elif feature_mode == \"ft2stage\":\n",
    "        x_train = df[df.test_tag == 0][common_columns+ft_columns]\n",
    "        x_test = df[df.test_tag == 1][common_columns+ft_columns]\n",
    "        \n",
    "    return x_train, x_test\n",
    "\n",
    "def classify(algorithm, param_mode):\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "\n",
    "    title = f\"{param_mode} {algorithm} + {feature_mode} {file_postfix[feature_mode]}\"    \n",
    "    report = title.strip() + \":\\n\"\n",
    "    \n",
    "    if param_mode == \"default\":\n",
    "        model = classifiers[algorithm][\"clf\"]\n",
    "    elif param_mode == \"specified\":\n",
    "        model = classifiers[algorithm][\"clf_with_params\"]\n",
    "    else:\n",
    "        model = RandomizedSearchCV(estimator=classifiers[algorithm][\"clf\"], param_distributions = classifiers[algorithm][\"random_grid\"], \n",
    "                               n_iter=100, verbose=2, cv=3, random_state=42, n_jobs=n_jobs)\n",
    "        \n",
    "    y_pred = [] \n",
    "    model.fit(x_train, y_train)\n",
    "    y_pred = model.predict(x_test)   \n",
    "    report += classification_report(y_test, y_pred)\n",
    "    \n",
    "    if(param_mode == \"tuned\"):\n",
    "        report += \"\\nbestparameters:\\n\" + str(model.best_params_) + '\\n'\n",
    "     \n",
    "    accuracyScore = accuracy_score(y_pred, y_test)\n",
    "    report += \"\\naccuracy score:\" + str(accuracyScore) + '\\n'\n",
    "    \n",
    "    report += \"\\n\\nduration: \" + str(datetime.now() - start_time)\n",
    "    \n",
    "    print(report)   \n",
    "    \n",
    "    with open(f\"results/{title}.txt\", \"w\") as f:\n",
    "        f.write(report)\n",
    "    \n",
    "    print(\"duration: \" + str(datetime.now() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_weight = ['balanced', None]\n",
    "class_weight = [None]\n",
    "\n",
    "n_jobs = 1\n",
    "random_state = 42\n",
    "\n",
    "rf_random_grid = {'bootstrap': [True, False],\n",
    "                  'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "                  'max_features': ['auto', 'log2', None],\n",
    "                  'min_samples_leaf': [1, 2, 4],\n",
    "                  'min_samples_split': [2, 5, 10],\n",
    "                  'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000],\n",
    "                  'class_weight': class_weight+[\"balanced_subsample\"]}\n",
    "\n",
    "svc_random_grid = {'C': np.logspace(-3, 2, 6), \n",
    "                   'gamma': ['auto', 'scale'],\n",
    "                   'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                   'class_weight' : class_weight}\n",
    "\n",
    "sgd_random_grid = {\"loss\": [\"hinge\", \"log\", \"modified_huber\", \"squared_hinge\", \"perceptron\"],\n",
    "                   \"penalty\": [\"l1\", \"l2\", \"elasticnet\"],\n",
    "                   \"l1_ratio\": 0.2*np.arange(0,6),\n",
    "                   'class_weight' : class_weight}\n",
    "\n",
    "knn_random_grid = {\"leaf_size\" : list(range(1,50)),\n",
    "                   \"n_neighbors\" : list(range(1,35)),\n",
    "                   \"p\": [1,2]}\n",
    "\n",
    "lr_random_grid = {'C' : np.logspace(-3, 2, 6),\n",
    "                  'penalty' : ['l2', 'none'],\n",
    "                  'solver' : ['newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "                  'class_weight' : class_weight}\n",
    "\n",
    "classifiers = {\n",
    "    \"mnb\" : {\"clf\" : MultinomialNB()},\n",
    "    \"gnb\" : {\"clf\" : GaussianNB()},\n",
    "    \"lr\" : {\"clf\" : LogisticRegression(n_jobs=n_jobs, random_state=random_state), \"random_grid\" : lr_random_grid, \"clf_with_params\" : LogisticRegression(n_jobs=n_jobs, random_state=random_state)},\n",
    "    \"sgd\" : {\"clf\" : SGDClassifier(n_jobs=n_jobs, random_state=random_state), \"random_grid\" : sgd_random_grid, \"clf_with_params\" : SGDClassifier(n_jobs=n_jobs, random_state=random_state)},\n",
    "    \"svc\" : {\"clf\" : SVC(random_state=random_state), \"random_grid\" : svc_random_grid, \"clf_with_params\" : SVC(random_state=random_state)},    \n",
    "    \"rf\" : {\"clf\" : RandomForestClassifier(n_jobs=n_jobs, random_state=random_state), \"random_grid\" : rf_random_grid, \"clf_with_params\" : RandomForestClassifier(n_jobs=n_jobs, random_state=random_state)},\n",
    "    \"knn\" : {\"clf\" : KNeighborsClassifier(n_jobs=n_jobs), \"random_grid\" : knn_random_grid, \"clf_with_params\" : KNeighborsClassifier(n_jobs=n_jobs)}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_columns = [\n",
    " 'comments', 'is_pull_request', 'has_milestone', 'num_of_assignees', 'reaction_total_count', 'numeric_association',\n",
    "\n",
    " 'num_of_sharps',\n",
    " 'num_of_at',\n",
    " 'num_of_codesnippets',\n",
    " 'num_of_functions',\n",
    " 'num_of_issues',\n",
    " 'num_of_paths',\n",
    " 'num_of_dates',\n",
    " 'num_of_times',\n",
    " 'num_of_urls',\n",
    " 'num_of_emails',\n",
    " 'num_of_obligations',\n",
    " 'num_of_qmark',\n",
    " \n",
    " 'title_lem_len',\n",
    " 'title_lem_words_num',\n",
    " 'body_lem_len',\n",
    " 'body_lem_words_num',\n",
    " 'title_alphabet_ratio',\n",
    " 'body_alphabet_ratio',\n",
    " \n",
    " 'title_sentistrenght_p',\n",
    " 'body_sentistrenght_p',\n",
    " 'title_subjectivity',\n",
    " 'body_subjectivity',\n",
    " 'positive_body_sentistrenght_n',\n",
    " 'positive_title_sentistrenght_n',\n",
    " 'positive_title_polarity',\n",
    " 'positive_body_polarity']\n",
    "\n",
    "ft_columns = ['ft_bug', 'ft_feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_postfix = {\"tfidf\": \"processed\", \"d2v\": \"500-500_proc-lem\", \"ft2stage\": \"\"}\n",
    "\n",
    "dataset_name = \"normdf_nontext_columns\"\n",
    "algorithm_name = \"rf\"\n",
    "param_mode = \"tuned\"   # param_modes = [\"defualt\", \"tuned\", \"specified\"]\n",
    "feature_mode = \"tfidf\"   # feature_modes = [\"d2v\", \"tfidf\", \"ft2stage\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"data/{dataset_name}.csv\")\n",
    "\n",
    "y_train = df[df.test_tag == 0].label_cat\n",
    "y_test = df[df.test_tag == 1].label_cat\n",
    "\n",
    "x_train, x_test = get_features(feature_mode, file_postfix=file_postfix[feature_mode])\n",
    "\n",
    "classify(algorithm_name, param_mode)\n",
    "print(\"******************done******************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
